{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed6d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'essential-BYOL/wandb/latest-run/files/essential-byol/1qtgce72/checkpoints/epoch=295-step=5326.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fa6dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.cifar import CIFAR100, MetaCIFAR100\n",
    "from dataset.mini_imagenet import ImageNet, MetaImageNet\n",
    "\n",
    "from dataset.mnist import MNIST, MetaMNIST\n",
    "from dataset.transform_cfg import transforms_options, transforms_list\n",
    "\n",
    "from meta_eval import meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999f1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt 관련된 사항들 추가 \n",
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--eval_freq', type=int, default=10, help='meta-eval frequency')\n",
    "parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
    "parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=10, help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=0.05, help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,80', help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
    "\n",
    "# dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "parser.add_argument('--dataset', type=str, default='miniImageNet', choices=['miniImageNet', 'tieredImageNet',\n",
    "                                                                                'CIFAR-FS', 'FC100'])\n",
    "parser.add_argument('--transform', type=str, default='A', choices=transforms_list)\n",
    "parser.add_argument('--use_trainval', action='store_true', help='use trainval set')\n",
    "\n",
    "# cosine annealing\n",
    "parser.add_argument('--cosine', action='store_true', help='using cosine annealing')\n",
    "\n",
    "# specify folder\n",
    "parser.add_argument('--model_path', type=str, default='', help='path to save model')\n",
    "parser.add_argument('--tb_path', type=str, default='', help='path to tensorboard')\n",
    "parser.add_argument('--data_root', type=str, default='../../datasets/CIFAR-FS', help='path to data root')\n",
    "\n",
    "# meta setting\n",
    "parser.add_argument('--n_test_runs', type=int, default=600, metavar='N',help='Number of test runs')\n",
    "parser.add_argument('--n_ways', type=int, default=3, metavar='N',help='Number of classes for doing each classification run')\n",
    "parser.add_argument('--n_shots', type=int, default=5, metavar='N',help='Number of shots in test')\n",
    "parser.add_argument('--n_queries', type=int, default=15, metavar='N',help='Number of query in test')\n",
    "parser.add_argument('--n_aug_support_samples', default=5, type=int,help='The number of augmented samples for each meta test sample')\n",
    "parser.add_argument('--test_batch_size', type=int, default=1, metavar='test_batch_size',help='Size of test batch)')\n",
    "\n",
    "parser.add_argument('-t', '--trial', type=str, default='1', help='the experiment id')\n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "opt.data_aug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83e8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 관련해서 불러오기 (일단 cifar)\n",
    "train_partition = 'train'\n",
    "train_trans, test_trans = transforms_options['D']\n",
    "\n",
    "train_loader = DataLoader(CIFAR100(args=opt, partition=train_partition, transform=train_trans),\n",
    "                                batch_size=opt.batch_size, shuffle=True, drop_last=True,\n",
    "                                num_workers=opt.num_workers)\n",
    "val_loader = DataLoader(CIFAR100(args=opt, partition='train', transform=test_trans),\n",
    "                                batch_size=opt.batch_size // 2, shuffle=False, drop_last=False,\n",
    "                                num_workers=opt.num_workers // 2)\n",
    "meta_testloader = DataLoader(MetaCIFAR100(args=opt, partition='test',\n",
    "                                                  train_transform=train_trans,\n",
    "                                                  test_transform=test_trans),\n",
    "                                     batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "                                     num_workers=opt.num_workers)\n",
    "meta_valloader = DataLoader(MetaCIFAR100(args=opt, partition='val',\n",
    "                                                 train_transform=train_trans,\n",
    "                                                 test_transform=test_trans),\n",
    "                                    batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "                                    num_workers=opt.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762245e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "model = resnet50()\n",
    "ckpt = torch.load(model_path)['state_dict']\n",
    "new_ckpt = dict()\n",
    "for key, value in ckpt.items() :\n",
    "    if 'online_encoder.encoder' in key :\n",
    "        new_ckpt[key] = value\n",
    "corrected_dict = { k.replace('online_encoder.encoder.', ''): v for k, v in new_ckpt.items() } # 제외\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.load_state_dict(corrected_dict, strict = False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6781e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans, test_trans = transforms_options['A']\n",
    "opt.data_root = '../../datasets/double_mnist'\n",
    "meta_testloader = DataLoader(MetaMNIST(args=opt, partition='test',\n",
    "                                                  train_transform=train_trans,\n",
    "                                                  test_transform=test_trans),\n",
    "                                     batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "                                     num_workers=opt.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8719b1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "600it [00:53, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.4167, test_std: 0.0068, time: 54.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get test result\n",
    "opt.test_batch_size = 32\n",
    "start = time.time()\n",
    "test_acc, test_std = meta_test(model, meta_testloader)\n",
    "test_time = time.time() - start\n",
    "print('test_acc: {:.4f}, test_std: {:.4f}, time: {:.1f}'.format(test_acc, test_std, test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777c837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82436df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
