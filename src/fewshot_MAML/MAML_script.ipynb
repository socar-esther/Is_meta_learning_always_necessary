{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd08aea-72ae-495c-9212-d91867566cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data.transforms import (NWays, KShots, LoadData, RemapLabels, ConsecutiveLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbc420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 54\n",
    "cuda = True\n",
    "shots = 1\n",
    "ways = 3\n",
    "\n",
    "meta_lr = 0.003\n",
    "fast_lr = 0.5\n",
    "meta_batch_size = 32\n",
    "adaptation_steps = 1\n",
    "num_iterations = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4c9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cpu')\n",
    "if cuda and torch.cuda.device_count():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76146d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0464dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer loop \n",
    "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
    "    data, labels = batch\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Separate data into adaptation/evalutation sets\n",
    "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
    "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
    "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
    "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
    "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
    "\n",
    "    # Adapt the model\n",
    "    for step in range(adaptation_steps):\n",
    "        adaptation_error = loss(learner(adaptation_data), adaptation_labels)\n",
    "        learner.adapt(adaptation_error)\n",
    "\n",
    "    # Evaluate the adapted model\n",
    "    predictions = learner(evaluation_data)\n",
    "    evaluation_error = loss(predictions, evaluation_labels)\n",
    "    evaluation_accuracy = accuracy(predictions, evaluation_labels)\n",
    "    return evaluation_error, evaluation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73e9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tasksets using the benchmark interface\n",
    "tasksets = l2l.vision.benchmarks.get_tasksets('cifarfs',\n",
    "                                                  train_samples=2*shots,\n",
    "                                                  train_ways=ways,\n",
    "                                                  test_samples=2*shots,\n",
    "                                                  test_ways=ways,\n",
    "                                                  root='../../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cc73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = resnet50(pretrained = False)\n",
    "model_path = './checkpoint/iter13616_acc0.604166679084301.pth'\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt)\n",
    "model.to(device)\n",
    "\n",
    "maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
    "opt = optim.Adam(maml.parameters(), meta_lr)\n",
    "loss = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21973565-3091-4778-9928-e702a7314785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시작\n",
    "for iteration in range(num_iterations):\n",
    "    opt.zero_grad()\n",
    "    meta_train_error = 0.0\n",
    "    meta_train_accuracy = 0.0\n",
    "    meta_valid_error = 0.0\n",
    "    meta_valid_accuracy = 0.0\n",
    "    \n",
    "    for task in range(meta_batch_size):\n",
    "        # Compute meta-training loss\n",
    "        learner = maml.clone()\n",
    "        batch = tasksets.train.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device)\n",
    "\n",
    "        evaluation_error.backward()\n",
    "        meta_train_error += evaluation_error.item()\n",
    "        meta_train_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "        # Compute meta-validation loss\n",
    "        # learner = maml.clone()\n",
    "        # batch = tasksets.validation.sample()\n",
    "        # evaluation_error, evaluation_accuracy = fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device)\n",
    "        # meta_valid_error += evaluation_error.item()\n",
    "        # meta_valid_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "    # Print some metrics\n",
    "    print('\\n')\n",
    "    print('Iteration', iteration)\n",
    "    print('Meta Train Error', meta_train_error / meta_batch_size)\n",
    "    print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
    "    # print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
    "    # print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
    "\n",
    "    # Average the accumulated gradients and optimize\n",
    "    for p in maml.parameters():\n",
    "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1979ece7-c29b-46e6-9ea3-fa0ce46b1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini imagenet test set 확인\n",
    "tasksets = l2l.vision.benchmarks.get_tasksets('mini-imagenet',\n",
    "                                                  train_samples=2*shots,\n",
    "                                                  train_ways=ways,\n",
    "                                                  test_samples=2*shots,\n",
    "                                                  test_ways=ways,\n",
    "                                                  root='../../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706f91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test Error 3.1253299694508314\n",
      "Meta Test Accuracy 0.3645833432674408\n"
     ]
    }
   ],
   "source": [
    "# test 진행\n",
    "meta_test_error = 0.0\n",
    "meta_test_accuracy = 0.0\n",
    "\n",
    "for task in range(meta_batch_size):\n",
    "    # Compute meta-testing loss\n",
    "    learner = maml.clone()\n",
    "    batch = tasksets.test.sample()\n",
    "    evaluation_error, evaluation_accuracy = fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device)\n",
    "\n",
    "    meta_test_error += evaluation_error.item()\n",
    "    meta_test_accuracy += evaluation_accuracy.item()\n",
    "    \n",
    "print('Meta Test Error', meta_test_error / meta_batch_size)\n",
    "print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99ac3ab-02fa-4adb-b797-d66a128f94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double mnist test set 확인\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "path_data = '../../datasets/double_mnist/test'\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = path_data, transform = transforms.ToTensor())\n",
    "mnist_test = l2l.data.MetaDataset(test_dataset)\n",
    "\n",
    "test_tasks = l2l.data.TaskDataset(mnist_test,\n",
    "                                       task_transforms=[\n",
    "                                            l2l.data.transforms.NWays(mnist_test, ways),\n",
    "                                            l2l.data.transforms.KShots(mnist_test, 2*shots),\n",
    "                                            l2l.data.transforms.LoadData(mnist_test),\n",
    "                                            l2l.data.transforms.RemapLabels(mnist_test),\n",
    "                                            l2l.data.transforms.ConsecutiveLabels(mnist_test),\n",
    "                                       ],\n",
    "                                       num_tasks=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb14972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Test Error 1.9164721611887217\n",
      "Meta Test Accuracy 0.3020833423361182\n"
     ]
    }
   ],
   "source": [
    "# test 진행\n",
    "meta_test_error = 0.0\n",
    "meta_test_accuracy = 0.0\n",
    "\n",
    "for task in range(meta_batch_size):\n",
    "    # Compute meta-testing loss\n",
    "    learner = maml.clone()\n",
    "    batch = test_tasks.sample()\n",
    "    evaluation_error, evaluation_accuracy = fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device)\n",
    "\n",
    "    meta_test_error += evaluation_error.item()\n",
    "    meta_test_accuracy += evaluation_accuracy.item()\n",
    "    \n",
    "print('Meta Test Error', meta_test_error / meta_batch_size)\n",
    "print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e09c50-ee3f-4aba-a70d-5c4f60687645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
