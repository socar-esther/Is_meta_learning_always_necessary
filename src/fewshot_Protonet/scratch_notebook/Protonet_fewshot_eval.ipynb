{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c1a73c-251f-403f-a1fc-d4d276a65b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test phase (1-gpu)\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data.transforms import NWays, KShots, LoadData, RemapLabels\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bd0cad-3f0f-4c36-9ab5-5575dd9b7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "max_epoch = 200\n",
    "test_shot = 1 # 1shot\n",
    "test_way = 3\n",
    "test_query = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40272a09-d84b-485c-a6e0-55837b94d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> check the trained model path : ./checkpoint/epoch50_loss1.414059302210808.pth\n"
     ]
    }
   ],
   "source": [
    "# get pretrained model (loss 기준 best model 확인)\n",
    "model_path = './checkpoint/epoch50_loss1.414059302210808.pth'\n",
    "model = resnet50(pretrained = False)\n",
    "ckpt = torch.load(model_path)\n",
    "corrected_dict = {k.replace('module.', '') : v for k, v in ckpt.items() }\n",
    "model.load_state_dict(corrected_dict)\n",
    "model = model.cuda()\n",
    "\n",
    "print(f'>> check the trained model path : {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4132454-2c1f-46d9-9e45-1ec84bf175ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "def pairwise_distances_logits(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    logits = -((a.unsqueeze(1).expand(n, m, -1) - b.unsqueeze(0).expand(n, m, -1))**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2c6cc4-98ba-4851-abdd-7a8e77abead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_adapt(model, batch, ways, shot, query_num, metric=None, device=None):\n",
    "    \n",
    "    if metric is None:\n",
    "        metric = pairwise_distances_logits\n",
    "\n",
    "    #device = model.cuda()\n",
    "    data, labels = batch\n",
    "    data = data.cuda()\n",
    "    labels = labels.cuda()\n",
    "    n_items = shot * ways\n",
    "\n",
    "    sort = torch.sort(labels)\n",
    "    data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "    labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "\n",
    "    embeddings = model(data)\n",
    "    support_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    selection = np.arange(ways) * (shot + query_num)\n",
    "    for offset in range(shot):\n",
    "        support_indices[selection + offset] = True\n",
    "    query_indices = torch.from_numpy(~support_indices)\n",
    "    support_indices = torch.from_numpy(support_indices)\n",
    "    support = embeddings[support_indices]\n",
    "    support = support.reshape(ways, shot, -1).mean(dim=1)\n",
    "    query = embeddings[query_indices]\n",
    "    labels = labels[query_indices].long()\n",
    "\n",
    "    logits = pairwise_distances_logits(query, support)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    acc = accuracy(logits, labels)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f7ea21-feb5-4cce-898c-f98456234870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "# dataset 정의\n",
    "dataset_nm = 'mnist' # miniImagenet, mnist\n",
    "\n",
    "if dataset_nm == 'cifarfs' : \n",
    "    path_data = '../../datasets'\n",
    "    test_dataset = l2l.vision.datasets.CIFARFS(root=path_data, mode='test', transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "    # dataloader 정의\n",
    "    test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "    test_transforms = [\n",
    "            NWays(test_dataset, test_way),\n",
    "            KShots(test_dataset, test_query + test_shot),\n",
    "            LoadData(test_dataset),\n",
    "            RemapLabels(test_dataset),\n",
    "    ]\n",
    "    test_tasks = l2l.data.TaskDataset(test_dataset,task_transforms=test_transforms,num_tasks=100000)\n",
    "    test_loader = DataLoader(test_tasks, pin_memory=True, shuffle=True)\n",
    "    \n",
    "elif dataset_nm == 'miniImagenet' :\n",
    "    path_data = '../../datasets'\n",
    "    test_dataset = l2l.vision.datasets.MiniImagenet(root=path_data, mode='test', download = True) # transform = transforms.ToTensor() # check\n",
    "    \n",
    "    # dataloader 정의\n",
    "    test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "    test_transforms = [\n",
    "            NWays(test_dataset, test_way),\n",
    "            KShots(test_dataset, test_query + test_shot),\n",
    "            LoadData(test_dataset),\n",
    "            RemapLabels(test_dataset),\n",
    "    ]\n",
    "    test_tasks = l2l.data.TaskDataset(test_dataset,task_transforms=test_transforms,num_tasks=100000)\n",
    "    test_loader = DataLoader(test_tasks, pin_memory=True, shuffle=True)\n",
    "    \n",
    "elif dataset_nm == 'mnist' :\n",
    "    path_data = '../../datasets/double_mnist/test'\n",
    "    test_dataset = torchvision.datasets.ImageFolder(root = path_data, transform = transforms.ToTensor())\n",
    "    test_dataset = l2l.data.MetaDataset(test_dataset)\n",
    "    test_transforms = [\n",
    "            NWays(test_dataset, test_way),\n",
    "            KShots(test_dataset, test_query + test_shot),\n",
    "            LoadData(test_dataset),\n",
    "            RemapLabels(test_dataset),\n",
    "    ]\n",
    "    \n",
    "    test_tasks = l2l.data.TaskDataset(test_dataset, task_transforms = test_transforms, num_tasks = 100000)\n",
    "    test_loader = DataLoader(test_tasks, pin_memory = True, shuffle = True)\n",
    "\n",
    "else :\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a5a20-9ec8-42d6-b49c-d9cf097223c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 500: 36.24(28.89)\n",
      "batch 1000: 35.85(44.44)\n"
     ]
    }
   ],
   "source": [
    "# check the test result\n",
    "loss_ctr = 0.0\n",
    "n_loss = 0.0\n",
    "n_acc = 0.0\n",
    "for i, batch in enumerate(test_loader, 1):\n",
    "    loss, acc = fast_adapt(model, batch, test_way, test_shot, test_query, metric = pairwise_distances_logits, device = None)\n",
    "    loss_ctr += 1\n",
    "    n_acc += acc\n",
    "    if i % 500 == 0 :\n",
    "        print('batch {}: {:.2f}({:.2f})'.format(i, n_acc/loss_ctr * 100, acc * 100))\n",
    "        \n",
    "print(f'Test Accuracy : {n_acc / loss_ctr * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ac5f1-5b12-4763-bc3a-1e4bc732498f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
