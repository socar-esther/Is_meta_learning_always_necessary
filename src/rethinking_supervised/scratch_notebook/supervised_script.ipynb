{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478a1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import model_pool\n",
    "from models.util import create_model\n",
    "\n",
    "from dataset.mini_imagenet import ImageNet, MetaImageNet\n",
    "# from dataset.mnist import MNIST, MetaMNIST\n",
    "from dataset.cifar import CIFAR100, MetaCIFAR100\n",
    "from dataset.sofar import SOFAR, MetaSOFAR\n",
    "from dataset.transform_cfg import transforms_options, transforms_list\n",
    "\n",
    "from util import adjust_learning_rate, accuracy, AverageMeter\n",
    "from eval.meta_eval import meta_test\n",
    "from eval.cls_eval import validate\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b78f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb2a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--eval_freq', type=int, default=10, help='meta-eval frequency')\n",
    "parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
    "parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=10, help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=4, help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=200, help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,80', help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
    "\n",
    "# dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50', choices=model_pool)\n",
    "parser.add_argument('--dataset', type=str, default='SOFAR', choices=['miniImageNet', 'tieredImageNet',\n",
    "                                                                                'CIFAR-FS', 'FC100'])\n",
    "parser.add_argument('--transform', type=str, default='A', choices=transforms_list)\n",
    "parser.add_argument('--use_trainval', action='store_true', help='use trainval set')\n",
    "\n",
    "# cosine annealing\n",
    "parser.add_argument('--cosine', action='store_true', help='using cosine annealing')\n",
    "\n",
    "# specify folder\n",
    "parser.add_argument('--model_path', type=str, default='', help='path to save model')\n",
    "parser.add_argument('--tb_path', type=str, default='', help='path to tensorboard')\n",
    "parser.add_argument('--data_root', type=str, default='', help='path to data root')\n",
    "\n",
    "# meta setting\n",
    "parser.add_argument('--n_test_runs', type=int, default=600, metavar='N',help='Number of test runs')\n",
    "parser.add_argument('--n_ways', type=int, default=2, metavar='N',help='Number of classes for doing each classification run')\n",
    "parser.add_argument('--n_shots', type=int, default=1, metavar='N', help='Number of shots in test')\n",
    "parser.add_argument('--n_queries', type=int, default=15, metavar='N',help='Number of query in test')\n",
    "parser.add_argument('--n_aug_support_samples', default=5, type=int,help='The number of augmented samples for each meta test sample')\n",
    "parser.add_argument('--test_batch_size', type=int, default=1, metavar='test_batch_size',help='Size of test batch)')\n",
    "parser.add_argument('-t', '--trial', type=str, default='1', help='the experiment id')\n",
    "\n",
    "opt = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46aaa165",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.dataset == 'CIFAR-FS' or opt.dataset == 'FC100':\n",
    "    opt.transform = 'D'\n",
    "\n",
    "if opt.use_trainval:\n",
    "    opt.trial = opt.trial + '_trainval'\n",
    "\n",
    "# set the path according to the environment\n",
    "if not opt.model_path:\n",
    "    opt.model_path = './models_pretrained'\n",
    "if not opt.tb_path:\n",
    "    opt.tb_path = './tensorboard'\n",
    "if not opt.data_root:\n",
    "    opt.data_root = '../../datasets/{}'.format(opt.dataset)\n",
    "else:\n",
    "    opt.data_root = '{}/{}'.format(opt.data_root, opt.dataset)\n",
    "opt.data_aug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4e2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "opt.model_name = '{}_{}_lr_{}_decay_{}_trans_{}'.format(opt.model, opt.dataset, opt.learning_rate,opt.weight_decay, opt.transform)\n",
    "\n",
    "if opt.cosine:\n",
    "    opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "if opt.adam:\n",
    "    opt.model_name = '{}_useAdam'.format(opt.model_name)\n",
    "\n",
    "opt.model_name = '{}_trial_{}'.format(opt.model_name, opt.trial)\n",
    "\n",
    "opt.n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dda47a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n",
      ">> iteration : 0\n",
      ">> iteration : 50\n",
      ">> iteration : 100\n",
      ">> iteration : 150\n",
      ">> iteration : 200\n",
      ">> iteration : 250\n",
      ">> iteration : 300\n",
      ">> iteration : 350\n",
      ">> iteration : 400\n",
      ">> iteration : 450\n",
      ">> iteration : 500\n",
      ">> iteration : 550\n",
      ">> iteration : 600\n",
      ">> iteration : 650\n",
      ">> iteration : 700\n",
      ">> iteration : 750\n",
      ">> iteration : 800\n",
      ">> iteration : 850\n",
      ">> iteration : 900\n",
      ">> iteration : 950\n",
      ">> iteration : 1000\n",
      ">> iteration : 1050\n",
      ">> iteration : 1100\n",
      ">> iteration : 1150\n",
      ">> iteration : 1200\n",
      ">> iteration : 1250\n",
      ">> iteration : 1300\n",
      ">> iteration : 1350\n",
      ">> iteration : 1400\n",
      ">> iteration : 1450\n",
      ">> iteration : 1500\n",
      ">> iteration : 1550\n",
      ">> iteration : 1600\n",
      ">> iteration : 1650\n",
      ">> iteration : 1700\n",
      ">> iteration : 1750\n",
      ">> iteration : 1800\n",
      ">> iteration : 1850\n",
      ">> iteration : 1900\n",
      ">> iteration : 1950\n",
      ">> iteration : 2000\n",
      ">> iteration : 2050\n",
      ">> iteration : 2100\n",
      ">> iteration : 2150\n",
      ">> iteration : 2200\n",
      ">> iteration : 2250\n",
      ">> iteration : 2300\n",
      ">> iteration : 2350\n",
      ">> iteration : 2400\n",
      ">> iteration : 2450\n",
      ">> iteration : 2500\n",
      ">> iteration : 2550\n",
      ">> iteration : 2600\n",
      ">> iteration : 2650\n",
      ">> iteration : 2700\n",
      ">> iteration : 2750\n",
      ">> iteration : 2800\n",
      ">> iteration : 2850\n",
      ">> iteration : 2900\n",
      ">> iteration : 2950\n",
      ">> iteration : 3000\n",
      ">> iteration : 3050\n",
      ">> iteration : 3100\n",
      ">> iteration : 3150\n",
      ">> iteration : 3200\n",
      ">> iteration : 3250\n",
      ">> iteration : 3300\n",
      ">> iteration : 3350\n",
      ">> iteration : 3400\n",
      ">> iteration : 3450\n",
      ">> iteration : 3500\n",
      ">> iteration : 3550\n",
      ">> iteration : 3600\n",
      ">> iteration : 3650\n",
      ">> iteration : 3700\n",
      ">> iteration : 3750\n",
      ">> iteration : 3800\n",
      ">> iteration : 3850\n",
      ">> iteration : 3900\n",
      ">> iteration : 3950\n",
      ">> iteration : 4000\n",
      ">> iteration : 4050\n",
      ">> iteration : 4100\n",
      ">> iteration : 4150\n",
      ">> iteration : 4200\n",
      ">> iteration : 4250\n",
      ">> iteration : 4300\n",
      ">> iteration : 4350\n",
      "Get data dictionary\n",
      "4400\n",
      ">> iteration : 0\n",
      ">> iteration : 50\n",
      ">> iteration : 100\n",
      ">> iteration : 150\n",
      ">> iteration : 200\n",
      ">> iteration : 250\n",
      ">> iteration : 300\n",
      ">> iteration : 350\n",
      ">> iteration : 400\n",
      ">> iteration : 450\n",
      ">> iteration : 500\n",
      ">> iteration : 550\n",
      ">> iteration : 600\n",
      ">> iteration : 650\n",
      ">> iteration : 700\n",
      ">> iteration : 750\n",
      ">> iteration : 800\n",
      ">> iteration : 850\n",
      ">> iteration : 900\n",
      ">> iteration : 950\n",
      ">> iteration : 1000\n",
      ">> iteration : 1050\n",
      ">> iteration : 1100\n",
      ">> iteration : 1150\n",
      ">> iteration : 1200\n",
      ">> iteration : 1250\n",
      ">> iteration : 1300\n",
      ">> iteration : 1350\n",
      ">> iteration : 1400\n",
      ">> iteration : 1450\n",
      ">> iteration : 1500\n",
      ">> iteration : 1550\n",
      ">> iteration : 1600\n",
      ">> iteration : 1650\n",
      ">> iteration : 1700\n",
      ">> iteration : 1750\n",
      ">> iteration : 1800\n",
      ">> iteration : 1850\n",
      ">> iteration : 1900\n",
      ">> iteration : 1950\n",
      ">> iteration : 2000\n",
      ">> iteration : 2050\n",
      ">> iteration : 2100\n",
      ">> iteration : 2150\n",
      ">> iteration : 2200\n",
      ">> iteration : 2250\n",
      ">> iteration : 2300\n",
      ">> iteration : 2350\n",
      ">> iteration : 2400\n",
      ">> iteration : 2450\n",
      ">> iteration : 2500\n",
      ">> iteration : 2550\n",
      ">> iteration : 2600\n",
      ">> iteration : 2650\n",
      ">> iteration : 2700\n",
      ">> iteration : 2750\n",
      ">> iteration : 2800\n",
      ">> iteration : 2850\n",
      ">> iteration : 2900\n",
      ">> iteration : 2950\n",
      ">> iteration : 3000\n",
      ">> iteration : 3050\n",
      ">> iteration : 3100\n",
      ">> iteration : 3150\n",
      ">> iteration : 3200\n",
      ">> iteration : 3250\n",
      ">> iteration : 3300\n",
      ">> iteration : 3350\n",
      ">> iteration : 3400\n",
      ">> iteration : 3450\n",
      ">> iteration : 3500\n",
      ">> iteration : 3550\n",
      ">> iteration : 3600\n",
      ">> iteration : 3650\n",
      ">> iteration : 3700\n",
      ">> iteration : 3750\n",
      ">> iteration : 3800\n",
      ">> iteration : 3850\n",
      ">> iteration : 3900\n",
      ">> iteration : 3950\n",
      ">> iteration : 4000\n",
      ">> iteration : 4050\n",
      ">> iteration : 4100\n",
      ">> iteration : 4150\n",
      ">> iteration : 4200\n",
      ">> iteration : 4250\n",
      ">> iteration : 4300\n",
      ">> iteration : 4350\n",
      "Get data dictionary\n"
     ]
    }
   ],
   "source": [
    "# get datasets\n",
    "opt.data_root = '../../datasets/sofar_v3/'\n",
    "train_partition = 'train'\n",
    "\n",
    "train_loader = DataLoader(SOFAR(opt.data_root, data_aug=True, partition=train_partition, transform=None),\n",
    "                                  batch_size=opt.batch_size, shuffle=True, drop_last=True,\n",
    "                                  num_workers=opt.num_workers)\n",
    "val_loader = DataLoader(SOFAR(opt.data_root, data_aug=True, partition='train', transform=None),\n",
    "                                batch_size=opt.batch_size // 2, shuffle=False, drop_last=False,\n",
    "                                num_workers=opt.num_workers // 2)\n",
    "n_cls = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c57a82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model name : resnet50, dataset : SOFAR\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = create_model(opt.model, n_cls, opt.dataset)\n",
    "\n",
    "print(f'>> model name : {opt.model}, dataset : {opt.dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2162c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "if opt.adam:\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=opt.learning_rate,weight_decay=0.0005)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(),lr=opt.learning_rate,momentum=opt.momentum,weight_decay=opt.weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if opt.n_gpu > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7654dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cosine annealing scheduler\n",
    "if opt.cosine:\n",
    "    eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, opt.epochs, eta_min, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d614f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ab4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, model, criterion, optimizer, opt):\n",
    "    \"\"\"One epoch training\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input = input.float()\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # ===================forward=====================\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        acc = accuracy(output, target)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        acc1.update(acc.item(), input.size(0))\n",
    "\n",
    "        # ===================backward=====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ===================meters=====================\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # tensorboard logger\n",
    "        pass\n",
    "\n",
    "        # print info\n",
    "        if idx % opt.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'.format(\n",
    "                   epoch, idx, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=acc1))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f}='.format(top1=acc1))\n",
    "\n",
    "    return acc1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    if opt.cosine:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        adjust_learning_rate(epoch, opt, optimizer)\n",
    "    print(\"==> training...\")\n",
    "\n",
    "    time1 = time.time()\n",
    "    train_acc, train_loss = train(epoch, train_loader, model, criterion, optimizer, opt)\n",
    "    time2 = time.time()\n",
    "    print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n",
    "\n",
    "    print('train_acc', train_acc, epoch)\n",
    "    print('train_loss', train_loss, epoch)\n",
    "\n",
    "    test_acc, test_loss = validate(val_loader, model, criterion, opt)\n",
    "\n",
    "    print(f'[epoch {epoch}] test_acc : {test_acc}')\n",
    "    print(f'[epoch {epoch}] test_loss : {test_loss}')\n",
    "\n",
    "    # regular saving\n",
    "    if best_acc < test_acc :\n",
    "        best_acc = test_acc\n",
    "        print('==> Saving...')\n",
    "        save_file = os.path.join('./checkpoint/best_model_sofar.pth'.format(epoch=epoch))\n",
    "        torch.save(model.state_dict(), save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ad80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Complete ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d10bf5",
   "metadata": {},
   "source": [
    "## Test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3f6341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model name : resnet50, model_path : ./checkpoint/best_model_sofar.pth\n"
     ]
    }
   ],
   "source": [
    "# checkpoint model path check\n",
    "model_nm = 'multi'\n",
    "\n",
    "\n",
    "if model_nm == 'imagenet' : \n",
    "    n_cls = 11\n",
    "    model = create_model(opt.model, n_cls, opt.dataset)\n",
    "    model = model.cuda()\n",
    "    print('Experiment with Imagenet weight frozen')\n",
    "elif model_nm == 'multi' :\n",
    "    n_cls = 11\n",
    "    #model_path = './checkpoint/ckpt_epoch_198.pth' # multi class classification\n",
    "    model_path = './checkpoint/best_model_sofar.pth' # Distill multi class classification\n",
    "    model = create_model(opt.model, n_cls, opt.dataset)\n",
    "    ckpt = torch.load(model_path)\n",
    "    corrected_dict = { k.replace('features.', ''): v for k, v in ckpt.items() } \n",
    "    model.load_state_dict(corrected_dict, strict = False)\n",
    "    model = model.cuda()\n",
    "    print(f'>> model name : {opt.model}, model_path : {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1216fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      ">> iteration : 0\n",
      ">> iteration : 50\n",
      ">> iteration : 100\n",
      ">> iteration : 150\n",
      ">> iteration : 200\n",
      ">> iteration : 250\n",
      ">> iteration : 300\n",
      ">> iteration : 350\n",
      "Get data dictionary\n"
     ]
    }
   ],
   "source": [
    "# check test datasets\n",
    "dataset_nm = 'sofar_test2' # choose : [cifarfs, miniImagenet, mnist]\n",
    "\n",
    "train_trans, test_trans = transforms_options[opt.transform]\n",
    "\n",
    "if dataset_nm == 'cifarfs' :\n",
    "    opt.data_root = '../../datasets/CIFAR-FS'\n",
    "    meta_testloader = DataLoader(MetaCIFAR100(args=opt, partition='test',\n",
    "                                                  train_transform=train_trans,\n",
    "                                                  test_transform=test_trans),\n",
    "                                     batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "                                     num_workers=opt.num_workers)\n",
    "elif dataset_nm == 'miniImagenet' :\n",
    "    train_trans, test_trans = transforms_options['A']\n",
    "    opt.data_root = '../../datasets/miniImageNet/'\n",
    "    meta_testloader = DataLoader(MetaImageNet(args=opt, partition='test',\n",
    "                                                  train_transform=train_trans,\n",
    "                                                  test_transform=test_trans),\n",
    "                                     batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "                                     num_workers=opt.num_workers)\n",
    "# elif dataset_nm == 'mnist' :\n",
    "#     # double MNIST (for few shot learning)\n",
    "#     opt.transfomr = 'A'\n",
    "#     train_trans, test_trans = transforms_options['A']\n",
    "#     opt.data_root = '../../datasets/double_mnist'\n",
    "#     meta_testloader = DataLoader(MetaMNIST(args=opt, partition='test',\n",
    "#                                                   train_transform=train_trans,\n",
    "#                                                   test_transform=test_trans),\n",
    "#                                      batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "#                                      num_workers=opt.num_workers)\n",
    "elif dataset_nm == 'sofar_test2' :\n",
    "    opt.data_root = '../../datasets/sanitized_test2_v2/'\n",
    "    meta_testloader = DataLoader(MetaSOFAR(args=opt, partition='test',\n",
    "                                                  train_transform=None,\n",
    "                                                  test_transform=None),\n",
    "                                     batch_size=opt.test_batch_size, shuffle=False, drop_last=False,\n",
    "                                     num_workers=opt.num_workers)\n",
    "else : \n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af207772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/functional.py:74: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "600it [02:59,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.5034444444444446, Test Std : 0.007219981553113744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "test_acc, test_std = meta_test(model, meta_testloader)\n",
    "print(f'Test Accuracy : {test_acc}, Test Std : {test_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54073d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944\n",
      ">> iteration : 0\n",
      ">> iteration : 50\n",
      ">> iteration : 100\n",
      ">> iteration : 150\n",
      ">> iteration : 200\n",
      ">> iteration : 250\n",
      ">> iteration : 300\n",
      ">> iteration : 350\n",
      ">> iteration : 400\n",
      ">> iteration : 450\n",
      ">> iteration : 500\n",
      ">> iteration : 550\n",
      ">> iteration : 600\n",
      ">> iteration : 650\n",
      ">> iteration : 700\n",
      ">> iteration : 750\n",
      ">> iteration : 800\n",
      ">> iteration : 850\n",
      ">> iteration : 900\n",
      "Get data dictionary\n"
     ]
    }
   ],
   "source": [
    "train_trans, test_trans = transforms_options[opt.transform]\n",
    "opt.data_root = '../../datasets/sofar_v3'\n",
    "sofar_test_loader = DataLoader(SOFAR(opt.data_root, data_aug=True, partition='test', transform=None),\n",
    "                                  batch_size=opt.batch_size, shuffle=True, drop_last=True,\n",
    "                                  num_workers=opt.num_workers)\n",
    "\n",
    "model.eval()\n",
    "sofar_test_output = list()\n",
    "for idx, (input, target) in enumerate(sofar_test_loader) :\n",
    "    input = input.float().cuda()\n",
    "    target = target.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "        \n",
    "    sofar_test_output.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e4bba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      ">> iteration : 0\n",
      ">> iteration : 50\n",
      ">> iteration : 100\n",
      ">> iteration : 150\n",
      ">> iteration : 200\n",
      ">> iteration : 250\n",
      ">> iteration : 300\n",
      ">> iteration : 350\n",
      "Get data dictionary\n"
     ]
    }
   ],
   "source": [
    "## test v2 set\n",
    "model.eval()\n",
    "opt.data_root = '../../datasets/sanitized_test2_v2/'\n",
    "test2_loader = DataLoader(SOFAR(opt.data_root, data_aug=True, partition='test', transform=None),\n",
    "                                  batch_size=opt.batch_size, shuffle=True, drop_last=True,\n",
    "                                  num_workers=opt.num_workers)\n",
    "test2_output = list()\n",
    "for idx, (input, target) in enumerate(test2_loader) :\n",
    "    input = input.float().cuda()\n",
    "    target = target.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "        \n",
    "    test2_output.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690ace7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      ">> iteration : 0\n",
      ">> iteration : 50\n",
      ">> iteration : 100\n",
      ">> iteration : 150\n",
      ">> iteration : 200\n",
      ">> iteration : 250\n",
      "Get data dictionary\n"
     ]
    }
   ],
   "source": [
    "## test v3 set \n",
    "opt.data_root = '../../datasets/sanitized_test3_v1/'\n",
    "test3_loader = DataLoader(SOFAR(opt.data_root, data_aug=True, partition='test', transform=None),\n",
    "                                  batch_size=opt.batch_size, shuffle=True, drop_last=True,\n",
    "                                  num_workers=opt.num_workers)\n",
    "\n",
    "model.eval()\n",
    "test3_output = list()\n",
    "for idx, (input, target) in enumerate(test3_loader) :\n",
    "    input = input.float().cuda()\n",
    "    target = target.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "        \n",
    "    test3_output.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "493c37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model output을 하나의 prob값으로 변경해서 저장헤야 함\n",
    "sofar_test_prob_list = list()\n",
    "\n",
    "for i in range(len(sofar_test_output)) :\n",
    "    for j in range(len(sofar_test_output[i].max(dim=1).values)) : \n",
    "        tmp = sofar_test_output[i].max(dim=1).values[j].item()\n",
    "        sofar_test_prob_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5470f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_prob_list = list()\n",
    "\n",
    "for i in range(len(test2_output)) :\n",
    "    for j in range(len(test2_output[i].max(dim=1).values)) : \n",
    "        tmp = test2_output[i].max(dim=1).values[j].item()\n",
    "        test2_prob_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3cf7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_prob_list = list()\n",
    "\n",
    "for i in range(len(test3_output)) :\n",
    "    for j in range(len(test3_output[i].max(dim=1).values)) : \n",
    "        tmp = test3_output[i].max(dim=1).values[j].item()\n",
    "        test3_prob_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e805ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### boxplot으로 확인\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ax.boxplot([sofar_test_prob_list, test2_prob_list, test3_prob_list])\n",
    "\n",
    "plt.title('Domain Shift', fontsize=20)\n",
    "plt.xticks([1, 2, 3], ['SOFAR_test', 'Test1', 'Test2'], fontsize = 20)\n",
    "plt.xlabel('Dataset', fontsize = 20)\n",
    "plt.ylabel('Logit', fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd40f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
