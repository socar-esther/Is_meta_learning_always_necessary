{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ab6db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from models import model_pool\n",
    "from models.util import create_model\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0ce18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support set에 해당하는 dataloader (5장만 가져오도록)\n",
    "normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "transform_train = transforms.Compose([\n",
    "                    transforms.Resize((550, 550)),\n",
    "                    transforms.RandomCrop(448, padding=8),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "support_dataset = ImageFolder(root='../../datasets/open_set_few_shot_retrieval_set/support_snow', transform=transform_train)\n",
    "support_loader = torch.utils.data.DataLoader(support_dataset, batch_size=5, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc1d93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query set이 loader에서 전체 돌면서 support set과의 mean(sim)을 확인해서 저장\n",
    "normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "transform_train = transforms.Compose([\n",
    "                    transforms.Resize((550, 550)),\n",
    "                    transforms.RandomCrop(448, padding=8),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "query_dataset = ImageFolder(root='../../datasets/open_set_few_shot_retrieval_set/query_set', transform=transform_train)\n",
    "query_loader = torch.utils.data.DataLoader(query_dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4419dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load\n",
    "model_path = './checkpoint/best_model_sofar_multi.pth'\n",
    "model = create_model('resnet50', 11, 'SOFAR')\n",
    "ckpt = torch.load(model_path)\n",
    "corrected_dict = { k.replace('features.', ''): v for k, v in ckpt.items() } \n",
    "model.load_state_dict(corrected_dict, strict = False)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b7f52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 제외하고 feature extractor만 가져오기\n",
    "model.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3f933a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기서 support set을 먼저 지정하기\n",
    "for idx, (img, target) in enumerate(support_loader) : \n",
    "    img = img.cuda()\n",
    "    target = target.cuda()\n",
    "    support_output = model(img)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b187e0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 401408])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_output[0].reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9dd6be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = dict()\n",
    "\n",
    "for idx, (img, target) in enumerate(query_loader) : \n",
    "    img = img.cuda()\n",
    "    target = target.cuda()\n",
    "    img_path = query_dataset.imgs[idx][0]\n",
    "    \n",
    "    query_vec = model(img)\n",
    "    query_vec = query_vec.cpu().detach().numpy()\n",
    "    \n",
    "    distance_list = list()\n",
    "    for i in range(len(support_output)) :\n",
    "        support_vec = support_output[i].reshape(1, -1)\n",
    "        support_vec = support_vec.cpu().detach().numpy()\n",
    "        dist = np.linalg.norm(support_vec - query_vec)\n",
    "        distance_list.append(dist)\n",
    "    avg_dist = np.mean(distance_list)\n",
    "    result_dict[img_path] = avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "686b357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value 기준으로 sort\n",
    "sorted_dict = sorted(result_dict.items(), key = lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "783861e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict_50 = sorted_dict[:50] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d776cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_list = list()\n",
    "\n",
    "for key, item in sorted_dict_50 : \n",
    "    top_50_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81cf8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(top_50_list)) :\n",
    "    if 'document' in top_50_list[i] :\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2cc30f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e7f8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더로 저장\n",
    "for i in range(len(top_50_list)) :\n",
    "    filenm = top_50_list[i].split('/')[-1]\n",
    "    dst_file_path = os.path.join('../../datasets/open_set_few_shot_retrieval_set/multi_euclidean_document/', filenm)\n",
    "    shutil.copy(top_50_list[i], dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d82f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
