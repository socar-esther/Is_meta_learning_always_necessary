{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b46a2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from models import model_pool\n",
    "from models.util import create_model\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "940bf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. get support set loader \n",
    "normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "transform_train = transforms.Compose([\n",
    "                    transforms.Resize((550, 550)),\n",
    "                    transforms.RandomCrop(448, padding=8),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "support_dataset = ImageFolder(root='../../datasets/open_set_few_shot_retrieval_set/support_document', transform=transform_train)\n",
    "support_loader = torch.utils.data.DataLoader(support_dataset, batch_size=5, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2ee9a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. get query set loader\n",
    "normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "transform_train = transforms.Compose([\n",
    "                    transforms.Resize((550, 550)),\n",
    "                    transforms.RandomCrop(448, padding=8),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "query_dataset = ImageFolder(root='../../datasets/open_set_few_shot_retrieval_set/query_set', transform=transform_train)\n",
    "query_loader = torch.utils.data.DataLoader(query_dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "79b195b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3. load the best pretrained model\n",
    "model_path = './checkpoint/best_model_sofar_multi.pth'\n",
    "model = create_model('resnet50', 11, 'SOFAR')\n",
    "ckpt = torch.load(model_path)\n",
    "corrected_dict = { k.replace('features.', ''): v for k, v in ckpt.items() } \n",
    "model.load_state_dict(corrected_dict, strict = False)\n",
    "model = model.cuda()\n",
    "\n",
    "model.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "708775ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. get the support set representation vector (5shot; for 5 support set samples )\n",
    "for idx, (img, target) in enumerate(support_loader) : \n",
    "    img = img.cuda()\n",
    "    target = target.cuda()\n",
    "    support_output = model(img)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d7d2dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5. Start Retrieval\n",
    "result_dict = dict()\n",
    "\n",
    "for idx, (img, target) in enumerate(query_loader) : \n",
    "    img = img.cuda()\n",
    "    target = target.cuda()\n",
    "    img_path = query_dataset.imgs[idx][0]\n",
    "    \n",
    "    query_vec = model(img)\n",
    "    query_vec = query_vec.cpu().detach().numpy()\n",
    "    \n",
    "    distance_list = list()\n",
    "    for i in range(len(support_output)) :\n",
    "        support_vec = support_output[i].reshape(1, -1)\n",
    "        support_vec = support_vec.cpu().detach().numpy()\n",
    "        #dist = np.linalg.norm(support_vec - query_vec) # euclidean distacne\n",
    "        dist = distance.cosine(support_vec, query_vec) # cosine distance\n",
    "        distance_list.append(dist)\n",
    "    avg_dist = np.mean(distance_list)\n",
    "    result_dict[img_path] = avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fbf5f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6. Similarity sort\n",
    "sorted_dict = sorted(result_dict.items(), key = lambda item: item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "873e646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6-1. Get the top50 simiilar samples\n",
    "sorted_dict_50 = sorted_dict[:50] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ea5704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_list = list()\n",
    "\n",
    "for key, item in sorted_dict_50 : \n",
    "    top_50_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "575e67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(top_50_list)) :\n",
    "    if 'document' in top_50_list[i] :\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ca8cea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "39fd8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7. save the result to the new folder\n",
    "for i in range(len(top_50_list)) :\n",
    "    filenm = top_50_list[i].split('/')[-1]\n",
    "    dst_file_path = os.path.join('../../datasets/open_set_few_shot_retrieval_set/multi_cosine_document/', filenm)\n",
    "    shutil.copy(top_50_list[i], dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e973ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5a3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
